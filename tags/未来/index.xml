<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>未来 on Glow's Blog</title><link>https://glows.github.io/tags/%E6%9C%AA%E6%9D%A5/</link><description>Recent content in 未来 on Glow's Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>glows</copyright><lastBuildDate>Wed, 10 Jan 2018 17:14:31 +0000</lastBuildDate><atom:link href="https://glows.github.io/tags/%E6%9C%AA%E6%9D%A5/index.xml" rel="self" type="application/rss+xml"/><item><title>比尔·乔伊：为什么未来不需要我们人类</title><link>https://glows.github.io/_posts/%E6%AF%94%E5%B0%94%E4%B9%94%E4%BC%8A%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9C%AA%E6%9D%A5%E4%B8%8D%E9%9C%80%E8%A6%81%E6%88%91%E4%BB%AC%E4%BA%BA%E7%B1%BB/</link><pubDate>Wed, 10 Jan 2018 17:14:31 +0000</pubDate><guid>https://glows.github.io/_posts/%E6%AF%94%E5%B0%94%E4%B9%94%E4%BC%8A%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9C%AA%E6%9D%A5%E4%B8%8D%E9%9C%80%E8%A6%81%E6%88%91%E4%BB%AC%E4%BA%BA%E7%B1%BB/</guid><description>(转载)为什么未来不需要我们人类 比尔·乔伊 在21世纪，我们威力无比的三种科技：机器人、基因工程和纳米技术正在使人类成为濒危物种。
自从我从事科技创造的那一刻起，我就关注其在伦理上的问题。但直到1998年秋天我才认识到我们在21世纪面临着多大的危险。这一不安始于我遇到雷·库兹维尔（Ray Kurzweil），一位伟大的发明家，发明了为盲人服务的阅读机，还有许多不可思议的机器。
我和雷（Ray Kurzweil）都是在佐治亚州Gilder市召开的远程通讯大会的发言者。会议结束后，我在旅店酒吧与他偶遇。当时我正在与约翰（John Searle），一位在加州大学佰克利分校研究意识问题的哲学家，坐在一起聊天。雷（Ray Kurzweil）走过来与我们攀谈起来。直至今日，我们谈论的内容依然困扰着我。
我没有听到雷（Ray Kurzweil）的演讲及其后来的座谈，而约翰（John Searle）有，他们现在重拾未完的话题。雷（Ray Kurzweil）认为技术进步的速度将会越来越快，我们将会成为机器人或者与机器人结合的合成人，或者与之类似的东西。但约翰不以为然，他认为这不可能发生，因为机器人不会有意识。
在听到这样的谈话之前，我一直认为有感觉的机器人只存在于科幻小说中。但现在，从一些值得尊重的人那里，我知道了那些机器人已经离我们不远了。我大吃一惊，特别是我知道雷（Ray Kurzweil）已经证明自己有资格有能力描绘并创造出这一未来。我现在已经知道新科技，比如基因工程、纳米技术，能帮助我们重新改造这个世界，但智能机器人的现状与未来使我感到惊奇。
诸如此类的技术突破会使人厌倦。我们几乎每天都能听到关于科技进步的新闻。但这次可不是一般的预言。在旅店的酒吧里，雷（Ray Kurzweil）给了我一本他即将出版的新书《智能机器的时代》的预印本。他在这本书中勾勒出了他心目中的乌托邦：通过机器人技术，人类将会得到几乎永生不灭的生命。在阅读这本书时，我心中的不安越来越强烈。我敢肯定，雷（Ray Kurzweil）低估了机器人技术的危险性，低估了这一技术造成严重后果的可能性。
我发现以下反乌托邦情景让自己寝食难安：
新卢德主义的挑战
首先让我们假定计算机科学家开发出了比人类更能干的智能机器。在这种情况下，所有的工作将由大量组织良好的机器系统完成，而人类不再需要进行劳动。我们可能会充许机器自主地作出决定，或者人们依然保留对机器的控制。这两种情况都有可能发生。
如果允许机器自主运行，由于我们不可能猜测出机器是如何得出结论的，所以也就无法推测这一结果。我们将会发现人类的命运将掌握在机器手中。也许有人会争论说人类不会愚蠢到把所有的权力移交给机器，但我们正在谈论的既不是人类把权力让度给机器，也不是机器有意攫取权力。我们谈论的是人类很容易陷入不得不接受机器的自主决定，从而依赖机器生存的境地。随着社会及其面对的问题越来越复杂，并且机器的智能越来越高，人类将让机器作出越来越重要的决定，不为其他，只是机器作出的决定要比人类明智得多。最终，由于保持系统正常运行的决策是如此复杂，人类的智能再也无法承担，而机器却能胜任愉快。人们再也无法简单地拨掉机器的电源，因为我们是如此依赖机器，关机无异于自杀！
另一方面，人类保持对机器的控制是有可能的。比如，在上面所说的情况下，相当部分的人仍然控制私人拥有的机器，象汽车、个人电脑之类。但控制大型机器系统的是极少数精英阶层，就象当今社会一样。但与现在相比有两点不同：由于科技进步，精英阶层对广大群众有了更大的控制权，并且由于人类劳动不再是必需的，广大群众也变成了整个系统无用而多余的负担。如果精英阶层是冷酷无情的，他们可能会简单地把这些人消灭殆尽。如果他们是仁慈的，可能会用宣传或其他精神上、生物上的技术来降低人口出生率，直至这些人灭绝，从而完全拥有这个世界。还有另外一种可能性，如果精英阶层是软心肠的自由主义者，他们可能会扮演牧羊人的角色来照顾其余的人类。他们将会满足每个人肉体上的需要，让孩子们健康地成长，每个人都会忙于有益身心健康的爱好，任何对此不满意的人都会受到“特殊照顾”以纠正他们的“问题”。当然，生命是如此没有意义，以至人们不得不接受生物或精神上的改造以去除他们对权力的欲望，或者使之“升华”成无害的嗜好。这些经过改造的人类在这样的社会中也许会感到快乐，但他们肯定是不自由的，他们就像动物园中被饲养的动物。
直到你读到这一页，你才发现以上内容的作者是是荻尔多·卡辛斯基，著名的“大学炸弹客”。我并不是卡辛斯基的辩护者。在他17年的恐怖活动中，用炸弹夺走了3个人的生命，还炸伤了很多人。其中一枚炸弹使我的朋友DavidGelernter严重受伤，戴维是我们这个时代最具天才与想象力的计算机科学家。就象我的很多同事一样，我感到我很有可能就是“大学炸弹客”的下一个袭击目标。
卡辛斯基的行为是谋杀和愚蠢的罪行，毫无疑问，在我眼中他是个卢德主义者，但简单地下此结论难以驳倒他的观点。虽然很难，但在上面一段论述中，我还是察觉到了一些真相，我感到我有责任来面对它。
我们不希望卡辛斯基想象的反乌托邦成为现实，但一个众所周知的关于设计与技术应用的问题可以用“墨菲定律”来描述：“会出错的，终将会出错”（事实上，应当称之为菲纳络定律，这一错误本身就证明了菲格纳真是英明无比！）抗生素的过度使用已经造成最严重的问题：抗生素耐药性危机和越来越多的危险细菌。与之类似的事情曾经发生过：想用DDT杀死传播虐疾的蚊子，却使之产生DDT耐药性，其幼虫也获得了对多种药物的耐药性基因。
诸如此类令人惊奇的事故清楚地表明：系统各部分相互之间的作用与反馈太过复杂，对系统的改变会引起连锁反应，难以预料最终结果。特别是把人类的活动也考虑进来后，情况就越发复杂了。
我开始向朋友们介绍《智能机器的时代》一书对对卡辛斯基言论的引用；我递给他们卡辛斯基的书，让他们阅读这些引文，然后观察当他们发现是谁写下这些文字时的反应。大约在这一段时间，我发现了汉斯·莫拉维克（Hans Moravec）的《机器人：通往非凡思维的纯粹机器》。莫拉维克是机器人研究领域的领军人物，他在卡耐基·梅隆大学创立并领导着世界上最大的机器人研究计划。这本书给了我更多的材料来考验我的朋友们。令人惊奇的是，那些材料大多支持卡辛斯基的论调。例如：
“近期（2000年早期）”一章
生物物种在遭遇到占优势的竞争者时几乎毫无生存的机会。一千万年以前，南北美洲被巴拿马地峡分开。南美洲就象今天的澳大利亚，到处繁衍着有袋类哺乳动物，有袋鼠、袋鹿和袋虎等等。当连接南北美洲的地峡升起后，北方在新陈代谢与神经系统上只占很少优势的胎生物种只用了几千年的时间就替换并灭绝了几乎所有的南方有袋类物种。
在完全自由竞争的市场上，占优势的机器人就会象北美胎生物种影响有南美有袋类物种一样影响人类的生存（也好象人类曾经影响无数其他物种一样）。机器人工业将会为了原材料、能源和空间展开激烈的竞争，其结果就是机器人的经济性超过人类。由于无法负担生活所需，人类将会被排挤出生存空间。
可能还有可能给人类留下喘息的空间，因为我们并不是生活在一个完全自由竞争的市场中。政府会强制执行一些非市场化政策，特别是税收。通过这一明智之举，政府的强制措施能支持人类在机器人劳动成果的基础以一种较高的生存状态繁衍生息。这一情况可能会持续很长时间。
这真是一本反乌托邦的生动教材，并且会让莫拉维克感到很不舒服。他继续讨论我们在21世纪的主要是：“制定法律来规范机器人工业的行为，确保与其持续的合作”。并描述了“一旦人类转变为毫无约束的超级智能机器人”会产生多么严重危险。在莫洛维克的观点里，机器人最终会战胜我们，人类毫无疑问将面结灭绝的命运。
我决定在此时此刻与我的朋友丹尼·希里斯（Dany Hillis）好好谈一谈。丹尼是生产并行超级计算机的Thinking Machines公司的创始人之一。我不光是太阳微系统公司的首席科学家，同时也是一个计算机设计者。丹尼在信息和物理科学方面的知识超过我认识的每一个人。丹尼还是一位值得关注的未来学家，他对未来进行了很长时间的思考，并在四年前创立了Long Now Foundation，他还为过去10000年制造了一台时钟，尝试刻画出人类历史上值得纪念的时间段（见“Test of Time”《时间测试》，《连线》2003年8月78页）。
因此我飞到洛杉矶与丹尼夫妇共进午餐。我倾其所有，向丹尼提出了一些困扰我的想法我思路供其考虑。丹尼的回答直指库兹维尔（Ray Kurzweil）设想的未来情景：人类与机器人合二为一的时代很快就会到来。这一回答令我大吃一惊。总而言之，他认为这一变化会逐渐成为现实，人们迟早对此会习以为常。
但我认为我没有完全地感到惊奇。我从丹尼那听到了对库兹维尔（Ray Kurzweil）书中内容的引用。他说：“虽然我象别人一样喜爱自己身体，但是如果我能依靠硅基肉体活上200岁，我会毫不犹豫地放弃它。”看上去丹尼已经对一变化过程及随之而来的危险听天由命了，而我却不能。
当谈论与思考关于库兹维尔（Ray Kurzweil）、卡辛斯基及莫拉维克（Hans Moravec）的事情时，我突然想到了20多年前读过的一本弗兰克·赫伯特（Frank Herbert）的科幻小说《白色瘟役》（The White Plague）。在小说中，一位分子生物学家因其父母妻儿被无原无故地谋杀而陷入疯狂。为了报复，他制造并散布了一种新研制的高度传染性的瘟役，用它来杀死很多经过选择的人（我们应当庆辛卡辛斯基只是个数学家，而不是分子生物学家）。我还记得《星际迷航》（Star Trek）中的博格人（Berg），一种具有毁灭倾向的半人半机械生物。类似博格人的灾难是科幻小说中经常出现的情节。这就是我为什么更早更关注这样的机器人反乌托邦的原因。为什么其他人不为这梦魇般的未来世界操一点心呢？
这一问题的部分答案在于我们偏狭的劣根性：喜欢新奇的东西、马上就能上手的东西、毫无诫心地接受它们。习惯于每天听到的科技新发现。我们已经处于这样一个阶段：21世纪最引人注目的科技：机器人、基因工程和纳米技术，在其到来之前就已经表面出了与众不同的巨大威力，特别是机器人、经过基因工程改造过的有机体、纳米技术具有相同的使危险扩大的因素：它们能自我复制。一枚炸弹只能响一声，但一个机器人能就自我复制成很多个，很快就会失去控制。
在过去25年中，我的大部分工作是计算机网络研究。在网络上发送与接收信息会造成失控复制。虽然计算机或计算机网络上的失控复制很讨厌，但是在最坏情况下也不过是使单台计算机无法正常工作或阻塞网络通讯、网络服务。而那些更新科技产品的失控自我复制会造成更大危险：它们会损害到物理世界。
这些科技都提出了数不清的美好承诺：库茨维尔在其机器人梦想中看到的近乎长生不老的前景激励我们不断前进，基因工程很快就能为大多数不能很快痊愈的疾病提供了治疗方法；纳米技术和纳米医疗能治愈更多疾病。所有这一切将会极大提高我们的平均寿命及生活质量。然而，对于其中任何一项技术，持续不断地微小、个别的进行会积累成威力巨大的力量及其伴随而来的巨大的危险。
20世纪有何与众不同？当然，产生大规模杀伤性武器（WMD）核武器、生物武器、化学武器的科技极具威力，并且这些武器具有巨大的威胁性。但建造核武器至少需要时间、稀少、事实上不可能得到的原材料以及高度保密的资料；生物武器和化学武器的研制也需要开展大规模的活动。
而21世纪的技术——基因工程、纳米技术和机器人（GNR）的威力是如此巨大，它们会孕育出新的事故及滥用方式。最危险的是，这些事故与滥用首先会在个人或小型组织就能企及的能力范围内。它们不需要巨大的开发能力或稀少的原材料，只要有相关技术知识就能利用它们。
因此，我们不光受到大规模杀伤性武器的威胁，还有技术知识产生的大规模杀伤力，它们的自我复制能力极大地扩展了其杀伤力。
我想以下所说绝对不是危言耸听：我们人类面临产生极端邪恶的最高可能性，这一邪恶的产生正由国家力量支持的大规模杀伤性武器转而到恐怖的极端个人。
没有什么指出我们将面对这样的问题。
我的生命被内心深处的热情驱使着提出问题、找寻答案。当我3岁时，我已经开始阅读，所以我的父亲把我送进了小学，我那时只能坐在校长的腿上听他讲故事。我很早就开始上学。然后跳级，我以难于置信的热情投入到书本之中进行学习。我提出了很多让大人们都很难解决的问题。
作为一个十多岁的少年，我对科技技术非常着迷。我希望成为一名“火腿”（业余无线电爱好者），但我没有钱买设备。“火腿”是那个时代的因特网，非常容易上瘾，也使人离群索居。暂且不论有没有钱，我母亲马上表示坚决反对，我不能成为一名“火腿”，因为我已经够孤僻的啦！
那时我没有什么亲密的朋友，但我沉醉在我丰富的想像之中。我中学时代，我发现了许多伟大的科幻小说家。特别是我仍然记得Heinleain的《穿着太空服去旅行》（Have Spacesuit with Travel）和阿西莫夫的《我，机器人》及其机器人三原则。我被关于太空旅行的描写深深迷住了，就想拥有一架望远镜来看一看天上的星星；由于我没有钱买或制作一架，我就从图书馆借来关于如何制造望远镜的书，通过阅读来安慰自己。我在想像的空间中自由翱翔。
星期四晚上我的父母会出去打保龄球。而我们这些小孩独自待在家中。星期四晚上是吉恩·罗顿巴里（Gene Roddenberry）最初的《星际迷航》（Star Trek）播出的时间，这个节目给我留下了深刻的映象。我开始接受这样一种理念：人类未来将在太空进行西部英雄式的冒险。罗顿巴里描绘的几个世纪后的情景有着重要的道德价值：遵守“第一守则”，不要干预任何技术水平较低的文明的发展。这些对我有着不可否认的吸引力；是精英人类，而不是机器人会支配我们的未来。罗顿巴里梦想成为我生命中不可或缺的一部分。
最脍炙人口的电视科幻片集《星空奇遇》，其中述及太空合众国的所有探险队都要遵守一条「第一守则」（prime directive），那就是。在未调查清楚及未得太空合众国批准前，不得干预任何文化水平较低的族类的自然发展。</description></item></channel></rss>